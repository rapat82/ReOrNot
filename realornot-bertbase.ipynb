{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real or Not? NLP with Disaster Tweets\n",
    "## Predict which Tweets are about real disasters and which ones are not\n",
    "Competition Description\n",
    "\n",
    "Twitter has become an important communication channel in times of emergency.\n",
    "The ubiquitousness of smartphones enables people to announce an emergency they’re observing in real-time. Because of this, more agencies are interested in programatically monitoring Twitter (i.e. disaster relief organizations and news agencies).\n",
    "\n",
    "But, it’s not always clear whether a person’s words are actually announcing a disaster. Take this example:\n",
    "\n",
    "\n",
    "Tweet source: https://twitter.com/AnyOtherAnnaK/status/629195955506708480\n",
    "\n",
    "\n",
    "The author explicitly uses the word “ABLAZE” but means it metaphorically. This is clear to a human right away, especially with the visual aid. But it’s less clear to a machine.\n",
    "\n",
    "In this competition, you’re challenged to build a machine learning model that predicts which Tweets are about real disasters and which one’s aren’t. You’ll have access to a dataset of 10,000 tweets that were hand classified. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\color{blue}{\\text{Summary of main results}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - We fine tune a BERT model for this task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - We take output of [cls] token from all layers of BERT model and use their average for better performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Cross Validation (CV) scores are obtained using 5-fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Accuracies of upto 85.5 % and F1 scores of upto 0.85 can be obtained using this approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - To run this notebook locally, change the path of data files and files for pretrained bert model accordingly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-cased-vocab.txt\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-multilingual-cased-vocab.txt\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-large-uncased-vocab.txt\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-large-cased-vocab.txt\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-uncased-vocab.txt\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-multilingual-uncased-vocab.txt\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-chinese-vocab.txt\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-large-uncased/bert_config.json\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-large-uncased/pytorch_model.bin\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-uncased/bert_config.json\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-uncased/pytorch_model.bin\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-cased/bert_config.json\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-cased/pytorch_model.bin\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-multilingual-cased/bert_config.json\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-multilingual-cased/pytorch_model.bin\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-multilingual-uncased/bert_config.json\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-multilingual-uncased/pytorch_model.bin\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-chinese/bert_config.json\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-chinese/pytorch_model.bin\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-large-cased/bert_config.json\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-large-cased/pytorch_model.bin\n",
      "/kaggle/input/nlp-getting-started/train.csv\n",
      "/kaggle/input/nlp-getting-started/test.csv\n",
      "/kaggle/input/nlp-getting-started/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_data = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('../input/pretrained-bert-models-for-pytorch/bert-base-uncased-vocab.txt',\n",
    "                                         do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize(input_list, m_len):\n",
    "    output_list = []\n",
    "    output_list_token_type_ids = []\n",
    "    output_list_attention_mask = []\n",
    "    for i, row in enumerate(input_list):\n",
    "        temp = tokenizer.encode_plus(row, max_length=m_len, \n",
    "                                            truncation_strategy='longest_first', \n",
    "                                            pad_to_max_length=True, return_tensors='pt')\n",
    "        output_list.append(temp['input_ids'])\n",
    "        output_list_token_type_ids.append(temp['token_type_ids'])\n",
    "        output_list_attention_mask.append(temp['attention_mask'])\n",
    "    output_tensor = torch.stack(output_list).squeeze()\n",
    "    output_tensor_ids = torch.stack(output_list_token_type_ids).squeeze()\n",
    "    output_tensor_mask = torch.stack(output_list_attention_mask).squeeze()\n",
    "    return output_tensor, output_tensor_ids, output_tensor_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_on_gpu=torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "bert_model_config = '../input/pretrained-bert-models-for-pytorch/bert-base-uncased/bert_config.json'\n",
    "bert_config = BertConfig.from_json_file(bert_model_config)\n",
    "bert_config.output_hidden_states=True\n",
    "bert_model = BertModel.from_pretrained('../input/pretrained-bert-models-for-pytorch/bert-base-uncased/', config = bert_config)        \n",
    "\n",
    "class reornot(nn.Module):\n",
    "    \n",
    "    def __init__(self, ):\n",
    "        \n",
    "        super(reornot, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.fc1 = nn.Linear(bert_config.hidden_size, 1) \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, tokens, ids, masks):\n",
    "        h = self.bert(tokens, ids, masks)[2]\n",
    "        cls_outs = torch.stack([layer[:,0,:] for layer in h], dim = 2)\n",
    "        cls_output = cls_outs.mean(2)\n",
    "        x = self.fc1(cls_output)\n",
    "        output = self.sigmoid(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_actual, y_pred):\n",
    "    y_ = np.round(np.array(y_pred))\n",
    "    return np.sum(y_actual == y_) / y_actual.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3, 98.958333% loss: 0.67 Average loss: 0.5003274992729226\n",
      "Epoch: 2/3, 98.958333% loss: 0.26 Average loss: 0.37597498918573063\n",
      "Epoch: 3/3, 98.958333% loss: 0.23 Average loss: 0.33007651086275774\n",
      "95.83% loss: 0.39, accuracy 0.86 Average val loss: 0.41958513110876083\n",
      "\n",
      "Average accuracy:  0.8315206290849674\n",
      "\n",
      "F1 Score 0.826426277808598\n",
      "\n",
      "Epoch: 1/3, 98.958333% loss: 0.35 Average loss: 0.4987368894120057\n",
      "Epoch: 2/3, 98.958333% loss: 0.44 Average loss: 0.37824069429188967\n",
      "Epoch: 3/3, 98.958333% loss: 0.34 Average loss: 0.32758076426883537\n",
      "95.83% loss: 0.43, accuracy 0.80 Average val loss: 0.41850362718105316\n",
      "\n",
      "Average accuracy:  0.8310227736928105\n",
      "\n",
      "F1 Score 0.8265041389169003\n",
      "\n",
      "Epoch: 1/3, 98.958333% loss: 0.40 Average loss: 0.4985437532886863\n",
      "Epoch: 2/3, 98.958333% loss: 0.30 Average loss: 0.3841154268011451\n",
      "Epoch: 3/3, 98.958333% loss: 0.10 Average loss: 0.3356547951698303\n",
      "95.83% loss: 0.32, accuracy 0.86 Average val loss: 0.38611518157025176\n",
      "\n",
      "Average accuracy:  0.839984170751634\n",
      "\n",
      "F1 Score 0.8354621610612258\n",
      "\n",
      "Epoch: 1/3, 98.958333% loss: 0.36 Average loss: 0.4968004338443279\n",
      "Epoch: 2/3, 98.958333% loss: 0.50 Average loss: 0.3908602655865252\n",
      "Epoch: 3/3, 98.958333% loss: 0.22 Average loss: 0.34390580793842673\n",
      "95.83% loss: 0.27, accuracy 0.92 Average val loss: 0.39806547077993554\n",
      "\n",
      "Average accuracy:  0.8326041666666667\n",
      "\n",
      "F1 Score 0.8293055197780803\n",
      "\n",
      "Epoch: 1/3, 98.958333% loss: 0.37 Average loss: 0.5058807842433453\n",
      "Epoch: 2/3, 98.958333% loss: 0.33 Average loss: 0.38224388876308996\n",
      "Epoch: 3/3, 98.958333% loss: 0.28 Average loss: 0.3343867769775291\n",
      "95.83% loss: 0.44, accuracy 0.82 Average val loss: 0.4266312047839165\n",
      "\n",
      "Average accuracy:  0.8238802083333333\n",
      "\n",
      "F1 Score 0.8200174027537299\n",
      "\n",
      "Fold-1: 0.8315206290849674\n",
      "Fold-2: 0.8310227736928105\n",
      "Fold-3: 0.839984170751634\n",
      "Fold-4: 0.8326041666666667\n",
      "Fold-5: 0.8238802083333333\n",
      "Fold-1: 0.826426277808598\n",
      "Fold-2: 0.8265041389169003\n",
      "Fold-3: 0.8354621610612258\n",
      "Fold-4: 0.8293055197780803\n",
      "Fold-5: 0.8200174027537299\n",
      "5-fold CV accuracy result: Mean: 0.8318023897058824 Standard deviation:0.00511922914607981\n",
      "5-fold CV F1 result: Mean: 0.827543100063707 Standard deviation:0.004995608122091096\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "m_len = 84\n",
    "n=5\n",
    "seed = 1072\n",
    "kf = KFold(n_splits=n, random_state=seed, shuffle=True)\n",
    "net = reornot()\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "net = net.to(device)\n",
    "model_name = 'init.net'\n",
    "checkpoint = {'state_dict': net.state_dict()}\n",
    "with open(model_name, 'wb') as f:\n",
    "    torch.save(checkpoint, f)\n",
    "res_acc = []\n",
    "res_f1 = []\n",
    "f1_s_old = 0.0\n",
    "for train_index, val_index in kf.split(train_df_data):\n",
    "    train_df = train_df_data.iloc[train_index]\n",
    "    val_df = train_df_data.iloc[val_index]\n",
    "    tweets_train = train_df['text'].values\n",
    "    tweets_val = val_df['text'].values\n",
    "    y_train = train_df['target'].values\n",
    "    y_val = val_df['target'].values\n",
    "    tweets_num, ids, masks = numericalize(tweets_train, m_len)\n",
    "    tweets_num_val, val_ids, val_masks = numericalize(tweets_val, m_len)\n",
    "    train_data = TensorDataset(tweets_num, ids, masks, torch.from_numpy(y_train))\n",
    "    val_data = TensorDataset(tweets_num_val, val_ids, val_masks, torch.from_numpy(y_val))\n",
    "    train_bs = 64\n",
    "    train_loader = DataLoader(train_data, shuffle = True, batch_size=train_bs)\n",
    "    valid_loader = DataLoader(val_data, shuffle = True, batch_size=train_bs)\n",
    "    with open('init.net', 'rb') as f:\n",
    "        checkpoint = torch.load(f)\n",
    "        net.load_state_dict(checkpoint['state_dict'])\n",
    "    criterion = nn.BCELoss()\n",
    "    opt = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "    net.train()\n",
    "    EPOCHS = 3\n",
    "    loss_vs_epoch = []\n",
    "    valloss_vs_epoch = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        losses = []\n",
    "        for i, (tokens, ids, masks, target) in enumerate(train_loader):\n",
    "            y_pred = net(tokens.long().to(device), ids.long().to(device), masks.long().to(device))\n",
    "            loss = criterion(y_pred, target[:, None].float().to(device))\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            losses.append(loss.item())\n",
    "            print('\\rEpoch: %d/%d, %f%% loss: %0.2f'% (epoch+1, EPOCHS, i/len(train_loader)*100, loss.item()), end='')\n",
    "        print(' Average loss:', np.mean(losses))\n",
    "    val_losses = []\n",
    "    net.eval()\n",
    "    avg_acc = 0\n",
    "    preds = []\n",
    "    originals = []\n",
    "    for i, (tokens, ids, masks, target) in enumerate(valid_loader):\n",
    "        y_pred = net(tokens.long().to(device), ids.long().to(device), masks.long().to(device))\n",
    "        loss = criterion(y_pred,  target[:, None].float().to(device))\n",
    "        acc = accuracy(target.cpu().numpy(), y_pred.detach().cpu().numpy().squeeze())\n",
    "        avg_acc += acc\n",
    "        val_losses.append(loss.item())\n",
    "        preds.append(y_pred.cpu().detach().numpy())\n",
    "        originals.append(target.cpu().detach().numpy())\n",
    "        print('\\r%0.2f%% loss: %0.2f, accuracy %0.2f'% (i/len(valid_loader)*100, loss.item(), acc), end='')\n",
    "    print(' Average val loss:', np.mean(val_losses))    \n",
    "    print('\\nAverage accuracy: ', avg_acc / len(valid_loader))\n",
    "    res_acc.append(avg_acc / len(valid_loader))\n",
    "    f1_s = f1_score(np.concatenate(originals).squeeze(), np.round(np.concatenate(preds)).squeeze(), average='macro')\n",
    "    print('\\nF1 Score',f1_s)\n",
    "    res_f1.append(f1_s)\n",
    "    print()\n",
    "    if f1_s > f1_s_old:\n",
    "        f1_s_old = f1_s\n",
    "        model_name = 'best_model.net'\n",
    "        checkpoint = {'state_dict': net.state_dict()}\n",
    "        with open(model_name, 'wb') as f:\n",
    "            torch.save(checkpoint, f)         \n",
    "for i, result in enumerate(res_acc, 1):\n",
    "    print(f\"Fold-{i}: {result}\")\n",
    "for i, result in enumerate(res_f1, 1):\n",
    "    print(f\"Fold-{i}: {result}\")\n",
    "print(f\"{n}-fold CV accuracy result: Mean: {np.mean(res_acc)} Standard deviation:{np.std(res_acc)}\")\n",
    "print(f\"{n}-fold CV F1 result: Mean: {np.mean(res_f1)} Standard deviation:{np.std(res_f1)}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('best_model.net', 'rb') as f:\n",
    "    checkpoint = torch.load(f)\n",
    "loaded = reornot()\n",
    "loaded.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv').fillna('')\n",
    "tweets_test = test_df['text'].values\n",
    "submission = pd.read_csv('../input/nlp-getting-started/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_num, ids, masks = numericalize(tweets_test, m_len)\n",
    "test_data = TensorDataset(tweets_num, ids, masks)\n",
    "test_bs = 2\n",
    "test_loader = DataLoader(test_data, shuffle = False, batch_size=test_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = loaded.to(device)\n",
    "loaded.eval()\n",
    "preds = []\n",
    "for i, (tokens, ids, masks) in enumerate(test_loader):\n",
    "    y_pred = loaded(tokens.long().to(device), ids.long().to(device), masks.long().to(device))\n",
    "    preds.append(y_pred.cpu().detach()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_list = []\n",
    "for i in range(len(test_loader)):\n",
    "    submit_list.append(preds[i].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsub = np.concatenate(submit_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = nsub.round().astype(int)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
